# TensorRT-Quantization
using TensorRT to quantize model and infer in GPU

## References
- [tensorrt docs](https://docs.nvidia.com/deeplearning/tensorrt/latest/getting-started/quick-start-guide.html)
- [install tensorrt](https://docs.nvidia.com/deeplearning/tensorrt/latest/installing-tensorrt/installing.html)
- [intro-quantization](https://docs.nvidia.com/deeplearning/tensorrt/archives/tensorrt-1070/developer-guide/index.html#intro-quantization)
- [Implementation of popular deep learning networks with TensorRT](https://github.com/wang-xinyu/tensorrtx)

## object detection
### YOLO
- [YOLOv8](./object_detection/YOLOv8/README.md)

## other
- [Int8 maybe slower than fp16](https://github.com/NVIDIA/TensorRT/issues/993)